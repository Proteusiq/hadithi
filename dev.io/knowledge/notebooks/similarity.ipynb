{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99462abe-1eb2-4988-8cc2-5c132a34027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Prayson W. Daniel\n",
      "\n",
      "Last updated: 2024-11-14T10:16:44.073511+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.10\n",
      "IPython version      : 8.29.0\n",
      "\n",
      "ollama: 0.3.3\n",
      "torch : 2.5.1\n",
      "\n",
      "Compiler    : Clang 15.0.0 (clang-1500.3.9.4)\n",
      "OS          : Darwin\n",
      "Release     : 23.5.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "%reload_ext watermark\n",
    "%watermark -uniz --author \"Prayson W. Daniel\" -vm -p ollama,torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72497d6d-5c16-4082-be36-9f237322a2a0",
   "metadata": {},
   "source": [
    "# Using Ollama\n",
    "```sh\n",
    "ollama pull mxbai-embed-large\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ffe163-e0f8-4011-bd77-fd31ab7762f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f235fc97-5fc1-47dd-9738-0d0c0913a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_cases = {\"case1\": \"I like ice cream\", \n",
    "               \"case2\":\"I don't like ice cream\", \n",
    "               \"case3\":\"I hate ice cream\", \n",
    "               \"case4\": \"I enjoy ice cream\"}\n",
    "results = {}\n",
    "for case, blob in tests_cases.items():\n",
    "   results[case] = torch.Tensor(ollama.embeddings(\n",
    "      model='nomic-embed-text',\n",
    "      prompt=blob,\n",
    ").get(\"embedding\")).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6328c4c-a8d4-4c97-9ab8-95893f5e6fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8803]), tensor([0.8436]), tensor([0.9540]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.cosine_similarity(results['case1'], results['case2']), \n",
    " F.cosine_similarity(results['case1'], results['case3']), \n",
    " F.cosine_similarity(results['case1'], results['case4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa818157-59d0-44c5-84d4-0c235011b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = ollama.Client(host=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220a1946-11af-487e-97ea-8be2c916d011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- case -- \n",
      "\n",
      "These two statements are contradictory, making them highly dissimilar. The similarity lies in the fact that they both express a preference or lack thereof for ice cream, but the tone and intention behind each statement are opposite, with one being positive and the other negative.\n",
      "\n",
      " -- case -- \n",
      "\n",
      "These two statements are contradictory, as they express opposite emotions towards the same thing (ice cream). The similarity lies in their extreme nature, with one statement being an enthusiastic endorsement and the other a strong rejection, highlighting the intensity of the speaker's feelings.\n",
      "\n",
      " -- case -- \n",
      "\n",
      "The two sentences are very similar, as they both express a positive sentiment towards ice cream. The only difference is that the first sentence uses \"like\" to describe the preference, while the second sentence uses \"enjoy\", which implies a stronger affection or appreciation for ice cream.\n"
     ]
    }
   ],
   "source": [
    "case1 = tests_cases.pop(\"case1\")\n",
    "for casen in tests_cases.values():\n",
    "    print(\"\\n -- case -- \\n\")\n",
    "    prompt=f'How similiar are: {case1} and {casen}. Give a short reasons why. ca. 2 sentence'\n",
    "    \n",
    "    output = client.generate(\n",
    "      \n",
    "      model=\"llama3.2\",\n",
    "      prompt=prompt,\n",
    "      options={  \n",
    "                \"seed\": 42,\n",
    "                \"temperature\": 0.0, \n",
    "                \"num_ctx\": 2048 # must be set for reproducibility\n",
    "            }\n",
    "    )\n",
    "    \n",
    "    print(output['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175de39c-e3fa-461e-94ad-9b334a0cc10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a58960-5077-4fd8-8260-780aaad4e7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge",
   "language": "python",
   "name": "knowledge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
